{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs:\n",
    "#    X: pandas.DataFrame, features\n",
    "#    y: pandas.Series, target variable\n",
    "#    K: number of features to select\n",
    "def min_redun_max_relev(X, y, k):\n",
    "    # compute F-statistics and initialize correlation matrix\n",
    "    F = pd.Series(f_regression(X, y)[0], index = X.columns)\n",
    "    corr = pd.DataFrame(.00001, index = X.columns, columns = X.columns)\n",
    "\n",
    "    # initialize list of selected features and list of excluded features\n",
    "    selected = []\n",
    "    not_selected = X.columns.to_list()\n",
    "\n",
    "    # initialize list of feature scores\n",
    "    scores = []\n",
    "    scores_ith = []\n",
    "\n",
    "    redundancy = []\n",
    "    relevancy = []\n",
    "    # repeat K times\n",
    "    for i in range(k):\n",
    "        # compute (absolute) correlations between the last selected feature and all the (currently) excluded features\n",
    "        if i > 0:\n",
    "            last_selected = selected[-1]\n",
    "            corr.loc[not_selected, last_selected] = X[not_selected].corrwith(X[last_selected]).abs().clip(.00001)\n",
    "\n",
    "        # compute FCQ score for all the (currently) excluded features (this is Formula 2)\n",
    "        score = F.loc[not_selected] / corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001)\n",
    "        relevancy.append(F.loc[not_selected])\n",
    "        redundancy.append(corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001))\n",
    "\n",
    "        scores_ith.append(score)\n",
    "        # find best feature, add it to selected and remove it from not_selected\n",
    "        best = score.index[score.argmax()]\n",
    "        selected.append(best)\n",
    "        not_selected.remove(best)\n",
    "\n",
    "        # add feature name and score to list of feature scores\n",
    "        scores.append((best, score[best]))\n",
    "        \n",
    "        # create DataFrame of feature scores\n",
    "        score_df = pd.DataFrame(scores, columns=['mRMR', 'Highest_score_each_iteration'])\n",
    "    return scores,selected,scores_ith,score_df,relevancy,redundancy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data):\n",
    "    labels_fof = [\"Mean\",\"Variance\",\"Median\",\"Mode\",\"Skewness\",\n",
    "              \"Kurtosis\",\"Energy\",\"EntropyFOS\",\"MinimalGrayLevel\",\n",
    "              \"MaximalGrayLevel\",\"CoefficientOfVariation\",\n",
    "              \"10Percentile\",\"25Percentile\",\"75Percentile\",\n",
    "              \"90Percentile\",\"HistogramWidth\"]\n",
    "    \n",
    "    df1 = pd.DataFrame({'': labels_fof})\n",
    "    \n",
    "    df_fof_cols = {}\n",
    "    \n",
    "    for i, image in enumerate(data):\n",
    "        first_order_features = {}\n",
    "        first_order_features['A_FOS'] = fos(image,None)\n",
    "        df_fof_cols[\"Image_\" + str(i+1)] = first_order_features['A_FOS'][0]\n",
    "    \n",
    "    df2 = pd.DataFrame(df_fof_cols)\n",
    "    \n",
    "    df_fof = pd.concat([df1, df2],\n",
    "                  axis = 1)\n",
    "    \n",
    "    labels_glcm = [\"ASM\", \"Contrast\", \"Correlation\",\n",
    "              \"SumOfSquaresVariance\", \"InverseDifferenceMoment\",\n",
    "               \"SumAverage\", \"SumVariance\", \"SumEntropy\",\n",
    "               \"EntropyGLCM\", \"DifferenceVariance\",\n",
    "               \"DifferenceEntropy\", \"Information1\",\n",
    "               \"Information2\", \"MaximalCorrelationCoefficient\"]\n",
    "    \n",
    "    df3 = pd.DataFrame({'': labels_glcm})\n",
    "    \n",
    "    df_glcm_cols = {}\n",
    "    for i, image in enumerate(data):\n",
    "        second_order_features = {}\n",
    "        second_order_features['A_GLCM'] = glcm_features(image, ignore_zeros=True)\n",
    "        df_glcm_cols[\"Image_\" + str(i+1)] = second_order_features['A_GLCM'][0]\n",
    "    \n",
    "    df4 = pd.DataFrame(df_glcm_cols)\n",
    "    \n",
    "    df_glcm = pd.concat([df3, df4],\n",
    "                  axis = 1)\n",
    "    \n",
    "    df = pd.concat([df_fof, df_glcm], \n",
    "                  ignore_index = True)\n",
    "    \n",
    "    # Use the values in column 1 as the index for the DataFrame\n",
    "    df = df.set_index('')\n",
    "\n",
    "    # Transpose the DataFrame and use the values from column 1 as new column headers\n",
    "    df_T = df.T.rename(columns=df.iloc[0])\n",
    "\n",
    "    # Remove the index name\n",
    "    df_T.index.name = None\n",
    "    \n",
    "    return df_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
